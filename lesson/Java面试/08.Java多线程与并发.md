### 进程和线程的区别
* 一个进程对应一个程序，互不共享资源，可记录程序运行的当前状态
* 单核CPU下，同时只有一个进程在执行，CPU分时间片分别执行不同的进程任务。进程在切换的时候，记录其内存空间和运行状态。
* 进程有多个子任务，子任务往往互无依赖，称为线程。线程之间共享资源，切换更快捷。粒度进一步到一个进程内部的并发

进程是资源分配的最小单位（PCB），线程是CPU调度的最小单位
* 所有进程相关的资源，都被记录在PCB上
* 进程是抢占处理机的调度单位；线程属于某个进程，共享其资源
* 线程只由堆栈寄存器、程序计数器和TCP组成

#### 区别
* 线程不能看做独立应用，进程有
* 进程有独立地址空间，互不影响，线程只是进程的不同执行路径
* 线程没有独立的地址空间，多进程的程序比多线程程序健壮（一个线程挂掉了，就等于一个进程挂掉了）
* 进程的切换比线程开销大

##### Java进程和线程的关系
* Java对操作系统提供的功能进行封装，包括进程和线程
* 运行一个Java程序会产生一个进程，一个进程包含至少一个线程
* 每个进程对应一个JVM实例，多个线程共享JVM里的堆
* Java采用单线程编程模型，程序会自动创建一个线程，即主线程。耗时的操作要放到子线程中去，避免阻塞
* 主线程可以创建子线程，原则上要后于子线程完成执行（主线程需要执行关闭等操作）

### start和run方法的区别
* start会创建新的子线程并启动
* run方法只是Thread的一个普通方法的调用

### Thread和Runnable是什么关系
* Thread是实现了Runnable接口的类，使得run支持多线程
* 因类的单一继承原则，推荐多使用Runnable接口

### 如何给run方法传参
* 构造函数传参
* 成员变量set传参
* 回调函数传参

### 如何实现处理线程的返回值、
* 主线程等待法：需要实现等待代码的逻辑
* 使用Thread类的join方法阻塞当前线程以等待子线程：粒度不够细（当子线程执行到某一程度的时候，执行操作）
* 通过Callable接口实现：通过FutureTask（本身是一个实现了Runnable接口的类，通过传入实现了Callable的类，启动线程执行入参类，调用isDone可以获得是否结束的状态，调用get方法会阻塞，直到入参类的call方法执行完毕，并且使get方法获得入参类call方法的返回值） Or 线程池获取（通过线程池的submit方法，增加callable实现类，并获得Future类，然后同样可以调用isDone和get方法）

### 线程的状态
* 新建NEW：尚未启动的线程（还未调用start）
* 运行Runnable（调用start之后）：包含Ready（位于线程池中，等待被线程调度选中，获取CPU的使用权，获取后变成Running状态）和Running（可运行线程获得了CPU的使用权，处于运行当中）
* 无限期等待（Waiting）：不会被分配CPU执行时间，需要显式地被唤醒（没有设置Timeout参数的Object.wait()方法或Thread.join()，LockSupport.part()方法）
* 限期等待（Timed Wariting）：在一定时间后会由系统自动唤醒（Thread.sleep()方法；设置了Timeout参数的Object.wait()方法；设置了Timeout参数的Thread.join()方法；LockSupport.parkNanos()方法；LockSupport.parkUntil()方法）
* 阻塞（Blocked）：等待获取排它锁
* 结束（Terminated）：已终止线程的状态，线程已经结束执行（线程的run或main方法执行完成）。终止后不能复生

##sleep和wait的区别
* sleep是Thread的方法，wait是Object的方法（都是native）
* sleep可以在任何地方使用；wait只能在synchronized方法或块中使用

本质区别

* Thread.sleep只会让出CPU，不会导致锁行为的改变
* Object.wait不仅让出CPU，还会释放已经占用的同步资源锁

### notify和nofityAll的区别
二者都是用于唤醒线程

##### 对象的锁池EntryList
（sleep后让出CPU）被阻塞的线程，进入一个地方（锁池），等待对象（而不是类）的锁释放

##### 对象的等待池WaitSet
线程（wait后释放对象的锁）进入等待池，不会去竞争对象的锁。被notify或notifyAll后，会进入锁池

#### 区别
* notifyAll会让所有处于等待池的线程，全部进入锁池去竞争获取锁的机会。这些进入锁池的线程，如果没有竞争到锁，只能继续在锁池等待
* notify只会随机选取一个处于等待池中的线程，进入锁池去竞争获取锁的机会

### yield
Thread.yield()会给线程调度器一个暗示：当前线程愿意让出CPU的使用权，但是线程调度器可能会忽略这个暗示

### 如何中断线程

已经被抛弃的方法：线程A调用线程B的stop方法，以终止线程B，这种方法太过暴力而且不安全（A并不知道B的实际执行情况，可能会导致B的清理工作无法完成，另外，线程B会马上释放锁，有可能引发数据不同步的问题）。
类似被抛弃的还有suspend和resume方法

##### 目前使用的方法
调用interrupt，通知线程应该中断了
* 如果线程处于被阻塞的状态，那么线程将会立即退出被阻塞状态，并抛出InterruptedException异常
* 如果线程处于正常活动状态，那么会将该线程的中断标志设置为true。被设置中断标志的线程将继续正常运行，不受影响

需要被调用的线程配合中断
* 在正常运行任务时，经常检查本线程的中断标志位，如果被设置了中断标志就自动停止线程


### synchronized
线程安全问题的主要诱因

* 存在共享数据（也称临界资源）
* 存在多条线程共同操作这些共享数据

解决问题的根本办法：  
同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再对共享数据进行操作

互斥锁的特性  
* 互斥性：同一时间只允许一个线程持有某个对象锁。也称为操作的原子性
* 可见性：确保锁在被释放之前，对共享变量所做的修改，对下一个获取该锁的线程是可见的
synchronized满足互斥锁的要求

synchronized锁的是对象

#### 获取的锁的分类
##### 获取对象锁
两种用法
1. 同步代码块（synchronized(this)，synchronized(类实例对象)），锁是小括号()中的实例对象
2. 同步非静态方法（synchronized method），锁是当前对象的实例对象
##### 获取类锁
两种方法
1. 同步代码块（synchronized(类.class)），锁是小括号()中的类对象（Class对象）
2. 同步静态方法（synchronized static method），锁是当前对象的类对象（Class对象）

#### 对象锁和类锁的总结
* 。。。。

类锁和对象锁互不干扰
只有需要获取锁，才会被阻塞，非同步的代码不会被阻塞

### synchronized的底层实现原理
#### 实现synchronized的基础
##### Java对象头
对象在内存中的布局
###### 实例数据
###### 对齐填充
###### 对象头

一般而言，synchronized的锁对象，是存在对象头里
对象头结构
###### Class Metadata Address
类型指针指向对象的类元数据，JVM通过这个指针确定该对象是哪个类的数据
###### Mark Word
存储对象的运行时数据，是实现轻量级锁和偏向锁的关键  
默认存储对象的hashCode，分带年龄，键类型，锁标志位等信息  

非固定长度

##### Monitor
每个Java对象天生自带了一把看不见的锁，叫做内部锁，也称Monitor、管程、监视器锁
可以理解为一种同步工具，也可以描述为一种同步机制或对象

Mark Work也存在重量级锁（synchronized对象锁）的信息，标识位10
它起始指向对象的Monitor
当Monitor被某个线程持有后，对象就处于锁定状态
JVM中，Monitor通过ObjectMonitor实现，位于虚拟机的源码，是通过C++实现的
Monitor内部存在等待池WaitSet和锁池EntryList，还有Owner指向持有对象的线程，Count代表持有锁的对象数量（应该只会有0和1吧）

###### 字节码文件级别的原理
monitorenter指向同步代码块的开始位置
monitorexit指明同步代码块的结束位置
为了保证方法异常时依然可以使二者配对，编译器会自动产生一个异常处理器，就是用来执行monitorexit指令的

而方法级的同步是隐式的，无需通过字节码指令控制，方法本身会有访问标志ACC_SYNCHRONIZED，来区分方法是否同步

重入：一个线程再次请求自己已经持有的对象锁的临界资源，请求将会成功 

#### 为什么有人会对synchronized嗤之以鼻
* 早期版本中，synchronized属于重量级锁，依赖于底层操作系统的Mutex Lock实现
* 线程之间切换需要从用户态转换到核心态，开销较大
* Java6之后，synchronized性能得到了很大的提升，研究出了很多锁机制

##### 自旋锁
* 许多情况下，共享数据的锁定状态持续时间较短，让CPU切换线程（挂起和恢复阻塞线程）不值得 ==> **让等待锁的线程在门外等待一会儿，但不放弃CPU的执行时间**（等待但不放弃的行为称为自旋）
* 通过让线程执行忙循环等待锁的释放，不让出CPU（比wait和sleep要流氓一些）
* 缺点：若锁被其他线程长时间占用，会带来许多性能上的开销 ==> 设定等待时间：PreBlockSpin

##### 自适应自旋锁（比自旋锁更加聪明一点）
* 自旋次数不再固定
* 由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定

##### 锁消除 - 更彻底的优化
* JIT编译时，对运行上下文进行扫描，去除不可能存在竞争的锁。例如，StringBuffer的append方法

##### 锁粗化 - 另一种极端
* 极端情况：一连串操作，都对同一个对象反复加锁和解锁，甚至是在循环中
* 通过扩大加锁的范围，避免反复加锁和解锁 

### synchronized的四种状态
* 无锁、偏向锁、轻量级锁、重量级锁，会随着竞争情况逐渐升级

锁膨胀的方向：无锁 < 偏向锁 < 轻量级锁 < 重量级锁

#### 偏向锁：减少同一线程获取锁的代价
* 大多数情况下，锁不存在多线程竞争，总是由同一线程多次获得

核心思想：
线程获得锁，则锁进入偏向模式，Mark Word也变成偏向锁结构（给这个线程单独开后门）。如果下次还是这个线程，无需同步，只需要检查Mark Word锁标记位为偏向锁 & 当前线程ID等于Mark Word的ThreadId即可

不适用于锁竞争比较激烈的多线程场合

#### 轻量级锁
由偏向锁升级而来，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，会发生此升级

适用场景：线程交替执行同步块

若存在同一时间多个线程访问同一个锁的情况，就会使轻量级锁膨胀为重量级锁

##### 轻量级锁详细过程
* 线程本地内存创建Look Record空间，将主内存中对象的Mark Word拷贝到Look Record空间，称之为Displaced Mark Word
* 虚拟机使用CAS操作，尝试把主内存对象的Mark Word更新为指向Look Record的指针，并且让Look Record的Owner指针指向主内存对象的Mark Word（互相指定）
* 若尝试更新指针成功，则Mark Word的锁标志设置为轻量级锁“00”
* 若尝试更新指针失败（有别人占用了锁），虚拟机先检查当前对象是否已经拥有此锁，如果没有，轻量级锁就膨胀为重量级锁，锁标志变为“10”，后面等待锁的线程**也**进入阻塞状态。此时当前线程尝试自旋

解锁过程
* 通过CAS操作，尝试吧线程中的Displaced Mark Word对象替换主内存对象的Mark Word
* 如果替换成功，整个过程就完成了
* 如果替换失败，说明有其他线程尝试过获取该锁（是否因为锁标志变了，所以失败？），就要在释放锁的同事，唤醒被挂起的线程（是指自旋的线程，还是阻塞状态等待锁的线程）

#### 汇总

|-锁-|-优点-|-缺点-|-使用场景-|
|偏向锁|加锁解锁不需要CAS操作，没有额外性能小号，和执行非同步方法相比仅存在纳秒级的差距|如果线程间存在锁竞争，会带来额外的锁撤销消耗|只有一个线程访问同步块或者同步方法的场景|
|轻量级锁|竞争的线程不会阻塞，提高了响应速度|若线程长时间抢不到锁，自旋会消耗CPU性能|线程交替执行同步块或者同步方法的场景|
|重量级锁|线程竞争不使用自旋，不会消耗CPU|线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗|追求吞吐量，同步块或者同步方法执行时间较长的场景|

### synchronized和ReentrantLock的区别
ReentrantLock（再入锁）

* 位于java.util.concurrent.locks包（JUC包）
* 和CountDownLatch、FutureTask、Semaphore一样基于AQS实现
* 能够实现比synchronized更细粒度的控制，如控制fairness
* 调用lock()之后，必须调用unlock()释放锁
* 性能未必比synchronized高，并且也是可重入的

#### ReentrantLock公平性的设置
* ReentrantLock fairLock = new ReentrantLock(true);
* 参数为true，倾向于将锁赋予等待时间最久的线程
* 公平锁：获取锁的顺序按先后调用lock方法的顺序（慎用：公平性机制会额外开销，而且Java一般不会出现线程饥饿的情况，所以除非特别需要，不要采用）
* 非公平锁：抢占的顺序不一定，看运气
* synchronized是非公平锁

#### ReentrantLock将锁对象化
* 判断是否有线程，或者某个特定线程，在排队等待获取锁
* 带超时的获取锁的尝试
* 感知有没有成功获取锁

#### 能否将wait/notify/notifyAll对象化
* java.util.concurrent.locks.Condition

ReentrantLock.getNewCondition()
.await()  --等待
.singal() --notify
Condition使用AQS实现

#### synchronized和ReentrantLock的区别
* synchronized是关键字，ReentrantLock是类
* ReentrantLock可以对获取锁的等待时间进行设置，避免死锁
* ReentrantLock可以获取各种锁的信息
* ReentrantLock可以灵活地实现多路通知
* 机制：sync操作Mark Word，lock调用Unsafe类的park()方法

### 什么是Java内存模型中的happens-before
Java内存模型即JMM，本身是一种抽象的概念，并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。

#### JMM中的主内存
* 存储Java实例对象
* 包括成员变量、类信息、常量、静态变量等
* 属于数据共享的区域，多线程并发操作时会引发线程安全问题

#### JMM中的工作内存
* 存储当前方法的所有本地变量信息（主内存中变量副本的拷贝），本地变量对其他线程不可见
* 字节码行号指示器、Native方法信息
* 属于线程私有数据区域，不存在线程安全问题

#### JMM与Java内存区域划分是不同的概念层次
* JMM描述的是一组规则，围绕原子性、有序性、可见性展开
* 相似点：存在共享区域和私有区域

#### 主内存与工作内存的数据存储类型以及操作方式归纳
* 方法里的基本数据类型本地变量将直接存储在工作内存的栈帧结构中
* 引用类型的本地变量：引用存储在工作内存中，实例存储在主内存中
* 成员变量、static变量、类信息均会被存储在主内存中
* 主内存共享的方式是线程各拷贝一份数据到工作内存，操作完成后刷新回主内存

### JMM如何解决可见性问题

#### 指令重排序需要满足的条件
* 在单线程环境下不能改变程序运行的结果
* 存在数据依赖关系的不允许重排序
* 上述两点其实是归结为一点：无法通过happens-before原则推导出来的，才能进行指令的重排序

#### A操作的结果需要对B操作可见，则A与B存在happens-before关系
#### happens-before的八大原则
* 程序次序规则
* 锁定规则
* volatile变量规则：写操作要先于读操作发生
* 传递规则
* 线程启动规则：start方法最先发生
* 线程中断规则：interrupt方法的调用先于被中断线程的代码检测到中断事件的发生
* 线程终结规则
* 对象终结规则

#### happens-before的概念
如果两个操作不满足上述任意一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序；
如果操作A happens-before 操作B，那么操作A在内存上所做的操作对操作B都是可见的

#### volatile：JVM提供的轻量级同步机制
* 保证被volatile修饰的共享变量对所有线程总是可见的
* 禁止指令重排序优化

#### volatile的可见性
多线程下不是线程安全的，除非对其的操作是原子性的（boolean的赋值是原子性的，++不是原子性）

#### volatile变量为何立即可见
* 当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值刷新到主内存中
* 当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效

#### volatile如何禁止重排优化
##### 内存屏障（Memory Barrier）
* 保证特定操作的执行顺序
* 保证某些变量的内存可见性

通过插入内存屏障指令禁止在内存屏障前后的指令执行重排序优化
强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本

### volatile和 synchronized 的区别
1. volatile本质是在告诉JVM当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住直到该线程完成变量操作为止
2. volatile仅能使用在变量级别；synchronized则可以使用在变量、方法 和类级别
3. volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量修改的可见性和原子性
4. volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞
5. volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化

### CAS（Compare and Swap）

#### 一种高效实现线程安全性的方法
* 支持原子更新操作,适用于计数器,序列发生器等场景
* 属于乐观锁机制,号称lock-free
* CAS操作失败时由开发者決定是继续尝试,还是执行别的操作

#### CAS思想
* 包含三个操作数 —— 内存位置（V）、预期原值（A）和新值（B）

#### CAS多数情况下对开发者来说是透明的
* J.U.C的atomic包提供了常用的原子性数据类型以及引用、数组等相关原子类型和更新操作工具,是很多线程安全程序的首选
* Unsafe类虽提供CAS服务,但因能够操纵任意内存地址读写而有隐患
* Java9以后,可以使用 Variable Handle API来替代 Unsafe

#### 缺点
* 若循环时间长，则开销很大
* 只能保证一个共享变量的原子操作
* ABA问题（原值改变过，后来又变回来了）  ==> 解决：AtomicStampedReference

### Java线程池
#### 利用 Executors创建不同的线程池满足不同场景的需求
1. newFixedThreadPool(int nThreads)
指定工作线程数量的线程池
2. newCachedThreadPool()
处理大量短时间工作任务的线程池
1)试图缓存线程并重用,当无缓存线程可用时,就会创建新的工作线程
2)如果线程闲置的时间超过阈值,则会被终止并移出缓存
3)系统长时间闲置的时候,不会消耗什么资源
3. newSingleThreadExecutor()
创建唯一的工作者线程来执行任务,如果线程异常结束,会有另一个线程取代它
4. newSingleThreadScheduledExecutor()与newScheduledThreadPool(int corePoolSize)
定时或者周期性的工作调度,两者的区别在于单一工作线程还是多个线程
5. newworkStealingPool()
内部会构建 ForkJoin pool,利用 working-stealing算法,并行地处理任务,不保证处理顺序

##### Fork/join框架
把大任务分割成若干个小任务并行执行，最终汇总每个小任务结果后得到大任务结果的框架
Work-Stealing算法：某个线程从其他队列里窃取任务来执行

#### 为什么要使用线程池
* 降低资源消耗
* 提高线程的可管理型

#### JUC的三个Executor接口
* Executor：运行新任务的简单接口，将任务提交和任务执行细节解耦
* ExecutorService：具备管理执行器和任务生命周期的方法，提交任务机制更完善
* ScheduledExecutorSerivce：支持Future和定期执行任务

#### ThreadPoolExecutor
有一个工作队列WorkQueue
排队完成后，就提交给工作线程集合（管理线程的创建（ThreadFactory）和销毁）

#### ThreadPoolExecutor的构造函数
* corePoolSize:核心线程数量
* maximum PoolSize:线程不够用时能够创建的最大线程数
* workQueue:任务等待队列
* keepAliveTime:抢占的顺序不一定,看运气
* threadFactory：创建新的线程，Executors.defaultThreadFactory()
* handler：线程池的饱和策略

##### handler:线程池的饱和策略
* AbortPolicy:直接抛出异常，这是默认策略
* CallerRunsPolicy:用调用者所在的线程来执行任务
* DiscardOldest Policy:丢弃队列中靠最前的任务，并执行当前任务
* Discard Policy:直接丢弃任务
* 实现RejectedExecutionHandlert接口的自定义handler

#### 新任务提交执行后的判断
* 如果运行的线程少于corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的
* 如果线程池中的线程数量大于等于corePoolSize且小于maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务
* 如果设置的 corePoolSize和maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交若EworkQueue未满，则将请求放workQueue中，等待有空闲的线程去从workQueue中取任务并处理
* 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务

#### 线程池的状态
* RUNNING：能接受新提交的任务，并且也能处理阻塞队列中的任务
* SHUTDOWN：不再接受新提交的任务，但可以处理存量任务
* STOP：不再接受新提交的任务，也不处理存量任务
* TIDYING：所有的任务都已终止
* TERMINATED：terminated()方法执行完后进入该状态

#### 线程池的大小如何选定
* CPU密集型：线程数=按照核数或者核数+1设定
* I/O密集型：线程数=CPU核数*（1+平均等待时间/平均工作时间）
